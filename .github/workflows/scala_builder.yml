name: Setup Scala/Spark Dependencies

on:
  workflow_dispatch: # Allows you to manually trigger this workflow from the GitHub UI
  push:
    branches:
      - main # Also triggers on pushes to the main branch (you can remove this if you only want manual triggers)

jobs:
  setup-env:
    runs-on: ubuntu-latest # Uses the latest Ubuntu runner

    steps:
      - name: Checkout Repository (Optional, but good practice)
        uses: actions/checkout@v4
        # Even though you have no code, checking out the repo sets up the workspace

      - name: Set up Java JDK 17
        uses: actions/setup-java@v4
        with:
          java-version: '17'
          distribution: 'temurin'
          # No caching options needed as we're not building a project yet

      - name: Install Scala 2.13.12
        run: |
          SCALA_VERSION="2.13.12"
          SCALA_TGZ="scala-${SCALA_VERSION}.tgz"
          SCALA_URL="https://downloads.lightbend.com/scala/${SCALA_VERSION}/${SCALA_TGZ}"
          SCALA_INSTALL_DIR="/opt/scala-${SCALA_VERSION}" # Define install directory

          echo "Downloading Scala ${SCALA_VERSION}..."
          curl -sL $SCALA_URL -o $SCALA_TGZ
          tar xvf $SCALA_TGZ -C /opt/ # Extract to /opt/

          # Add Scala's bin directory to the PATH for the CURRENT shell session
          # AND for subsequent steps.
          echo "Adding ${SCALA_INSTALL_DIR}/bin to PATH for current and subsequent steps."
          echo "${SCALA_INSTALL_DIR}/bin" >> $GITHUB_PATH # For subsequent steps
          export PATH="${SCALA_INSTALL_DIR}/bin:$PATH"  # For the current step

          echo "--- Scala Installation Details ---"
          scala -version
          scalac -version
          echo "----------------------------------"

      - name: Verify Spark 3.5.0 Environment Preparation
        run: |
          SPARK_VERSION="3.5.0"
          SPARK_PACKAGE="spark-${SPARK_VERSION}-bin-hadoop3" # Common Spark distribution name
          # Using Apache archive for stability, check for latest if needed:
          SPARK_URL="https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/${SPARK_PACKAGE}.tgz"
          SPARK_INSTALL_DIR="/opt/${SPARK_PACKAGE}" # Define install directory

          echo "Attempting to download a portion of Spark ${SPARK_VERSION}..."
          curl -sL $SPARK_URL -o ${SPARK_PACKAGE}.tgz
          tar xvf ${SPARK_PACKAGE}.tgz -C /opt/

          # Add Spark's bin to PATH for the CURRENT shell session
          # AND for subsequent steps.
          echo "Adding ${SPARK_INSTALL_DIR}/bin to PATH for current and subsequent steps."
          echo "${SPARK_INSTALL_DIR}/bin" >> $GITHUB_PATH # For subsequent steps
          export PATH="${SPARK_INSTALL_DIR}/bin:$PATH" # For the current step

          echo "--- Spark Installation Details ---"
          echo "Verifying Spark command availability. This might take a moment..."
          which spark-shell || { echo "spark-shell command not found!"; exit 1; }
          echo "Spark commands are available in PATH."
          echo "----------------------------------"

      - name: Final Environment Check
        run: |
          echo "--- Final Environment Check ---"
          echo "JAVA_HOME: $JAVA_HOME"
          echo "PATH: $PATH"
          java -version
          scala -version
          spark-shell --version # This will print Spark version and exit
          echo "-------------------------------"